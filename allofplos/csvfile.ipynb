{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import csv\n",
    "pmcdir = 'pmc_articles'\n",
    "from plos_corpus import (corpusdir, get_article_pubdate, check_if_uncorrected_proof, listdir_nohidden,\n",
    "                         get_article_xml, file_to_doi, doi_to_file)\n",
    "\n",
    "from samples.corpus_analysis import (get_plos_article_type, get_article_dtd, get_random_list_of_dois, \n",
    "                                     get_related_retraction_article, check_article_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_metadata(article_file, size='small'):\n",
    "    \"\"\"\n",
    "    For an individual article in the PLOS corpus, create a tuple of a set of metadata fields sbout that corpus.\n",
    "    Make it small, medium, or large depending on number of fields desired.\n",
    "    :param article_file: individual local PLOS XML article\n",
    "    :param size: small, medium or large, aka how many fields to return for each article\n",
    "    :return: tuple of metadata fields\n",
    "    \"\"\"\n",
    "    doi = file_to_doi(article_file)\n",
    "    filename = os.path.basename(article_file).rstrip('.xml')\n",
    "    title = get_article_title(article_file)\n",
    "    journal = get_plos_journal(article_file)\n",
    "    jats_article_type = check_article_type(article_file)\n",
    "    plos_article_type = get_plos_article_type(article_file)\n",
    "    dtd_version = get_article_dtd(article_file)\n",
    "    dates = get_article_dates(article_file, string=True)\n",
    "    (pubdate, collection, received, accepted) = ('','','','')\n",
    "    pubdate = dates['epub']\n",
    "    try:\n",
    "        collection = dates['collection']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        received = dates['received']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        accepted = dates['accepted']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    metadata = [doi, filename, title, journal, jats_article_type, plos_article_type, dtd_version, pubdate,\n",
    "                received, accepted, collection]\n",
    "    metadata = tuple(metadata)\n",
    "    if len(metadata) == 11:\n",
    "        return metadata\n",
    "    else:\n",
    "        print('Error in {}: {} items'.format(article_file, len(article_file)))\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plos_journal(article_file, caps_fixed=True):\n",
    "    \"\"\"\n",
    "    For an individual PLOS article, get the journal it was published in.\n",
    "    :param article_file: individual local PLOS XML article\n",
    "    :param caps_fixed: whether to render the journal name correctly or as-is\n",
    "    :return: PLOS journal at specified xpath location\n",
    "    \"\"\"\n",
    "    journal = get_article_xml(article_file=article_file,\n",
    "                              tag_path_elements=[\"/\",\n",
    "                                                 \"article\",\n",
    "                                                 \"front\",\n",
    "                                                 \"journal-meta\",\n",
    "                                                 \"journal-title-group\",\n",
    "                                                 \"journal-title\"])\n",
    "    try:\n",
    "        journal = journal[0].text\n",
    "    except IndexError:\n",
    "        print('Error in journal name for {}'.format(article_file))\n",
    "    if caps_fixed:\n",
    "        journal = journal.split()\n",
    "        if journal[0].lower() == 'plos':\n",
    "            journal[0] = \"PLOS\"\n",
    "        journal = (' ').join(journal)\n",
    "    return journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PLOS Computational Biology'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_file = listdir_nohidden(corpusdir)[4638]\n",
    "get_plos_journal(article_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_article_title(article_file):\n",
    "    \"\"\"\n",
    "    For an individual PLOS article, get its title.\n",
    "    :param article_file: individual local PLOS XML article\n",
    "    :return: article title at specified xpath location\n",
    "    \"\"\"\n",
    "    title = get_article_xml(article_file=article_file,\n",
    "                            tag_path_elements=[\"/\",\n",
    "                                               \"article\",\n",
    "                                               \"front\",\n",
    "                                               \"article-meta\",\n",
    "                                               \"title-group\",\n",
    "                                               \"article-title\"])\n",
    "    return title[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_article_date(date_element, date_format='%d %m %Y'):\n",
    "    \"\"\"\n",
    "    For an article date element, convert XML to a datetime object\n",
    "    :param date_format: string format used to convert to datetime object\n",
    "    :return: datetime object\n",
    "    \"\"\"\n",
    "    day = ''\n",
    "    month = ''\n",
    "    year = ''\n",
    "    for item in date_element.getchildren():\n",
    "        if item.tag == 'day':\n",
    "            day = item.text\n",
    "        if item.tag == 'month':\n",
    "            month = item.text\n",
    "        if item.tag == 'year':\n",
    "            year = item.text\n",
    "    if day:\n",
    "        date = (day, month, year)\n",
    "        string_date = ' '.join(date)\n",
    "        date = datetime.datetime.strptime(string_date, date_format)\n",
    "    elif month:\n",
    "        date = (month, year)\n",
    "        string_date = ' '.join(date)\n",
    "        date = datetime.datetime.strptime(string_date, '%m %Y')\n",
    "    elif year:\n",
    "        date = year\n",
    "        date = datetime.datetime.strptime(date, '%Y')\n",
    "    else:\n",
    "        print('date error')\n",
    "        date = ''\n",
    "    return date\n",
    "\n",
    "def get_article_dates(article_file, string=False):\n",
    "    \"\"\"\n",
    "    For an individual article, get all of its dates\n",
    "    :param article_file: file path/DOI of the article\n",
    "    :return: dictionary of date types mapped to datetime objects for that article\n",
    "    \"\"\"\n",
    "    dates = {}\n",
    "\n",
    "    tag_path_1 = [\"/\",\n",
    "                  \"article\",\n",
    "                  \"front\",\n",
    "                  \"article-meta\",\n",
    "                  \"pub-date\"]\n",
    "    raw_xml_1 = get_article_xml(article_file=article_file,\n",
    "                              tag_path_elements=tag_path_1)\n",
    "    for element in raw_xml_1:\n",
    "        pub_type = element.get('pub-type')\n",
    "        date = parse_article_date(element)\n",
    "        dates[pub_type] = date\n",
    "\n",
    "    tag_path_2 = [\"/\",\n",
    "                  \"article\",\n",
    "                  \"front\",\n",
    "                  \"article-meta\",\n",
    "                  \"history\"]        \n",
    "    raw_xml_2 = get_article_xml(article_file=article_file,\n",
    "                              tag_path_elements=tag_path_2)\n",
    "    for element in raw_xml_2:\n",
    "        for part in element:\n",
    "            date_type = part.get('date-type')\n",
    "            date = parse_article_date(part)\n",
    "            dates[date_type] = date\n",
    "    if 'received' in dates and 'accepted' in dates:\n",
    "        if not dates['received'] <= dates['accepted'] <= dates['epub']:\n",
    "            print('{} dates not in correct order: {}'.format(article_file, dates))\n",
    "    if string:\n",
    "        for key, value in dates.items():\n",
    "            dates[key] = value.strftime('%Y-%m-%d')\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corpus_metadata(article_list=None):\n",
    "    \"\"\"\n",
    "    Run get_article_metadata() on a list of files, by default every file in corpusdir\n",
    "    :param article_list: list of articles to run it on\n",
    "    :return: list of tuples for each article\n",
    "    \"\"\"\n",
    "    if article_list is None:\n",
    "        article_list = listdir_nohidden(corpusdir)\n",
    "    corpus_metadata = [get_article_metadata(article) for article in article_list]\n",
    "    return corpus_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corpus_metadata_to_csv(corpus_metadata=None):\n",
    "    \"\"\"\n",
    "    Convert list of tuples from get_article_metadata to csv\n",
    "    :param corpus_metadata: the list of tuples, defaults to creating from corpusdir\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if corpus_metadata is None:\n",
    "        corpus_metadata = get_corpus_metadata()\n",
    "    with open('allofplos_metadata.csv', 'w') as out:\n",
    "        csv_out = csv.writer(out)\n",
    "        csv_out.writerow(['doi', 'filename', 'title', 'journal', 'jats_article_type', 'plos_article_type',\n",
    "                          'dtd_version', 'pubdate', 'received', 'accepted', 'collection'])\n",
    "        for row in corpus_metadata:\n",
    "            csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-6fa4920be814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marticle_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoi_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_random_list_of_dois\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorpus_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_corpus_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-182-e2510c1ee8c0>\u001b[0m in \u001b[0;36mget_corpus_metadata\u001b[0;34m(article_list)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marticle_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0marticle_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistdir_nohidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcorpus_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_article_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-182-e2510c1ee8c0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marticle_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0marticle_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistdir_nohidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcorpus_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_article_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-8410201fd184>\u001b[0m in \u001b[0;36mget_article_metadata\u001b[0;34m(article_file, size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_article_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mjournal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_plos_journal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mjats_article_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_article_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplos_article_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_plos_article_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-176-18454e172fc2>\u001b[0m in \u001b[0;36mget_plos_journal\u001b[0;34m(article_file, caps_fixed)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                  \u001b[0;34m\"journal-title-group\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                  \"journal-title\"])\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mjournal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjournal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcaps_fixed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mjournal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjournal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "article_files = [doi_to_file(doi) for doi in get_random_list_of_dois(count=1000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in journal name for allofplos_xml/journal.pone.0043777.xml\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-933d53af852c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_corpus_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-182-e2510c1ee8c0>\u001b[0m in \u001b[0;36mget_corpus_metadata\u001b[0;34m(article_list)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marticle_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0marticle_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistdir_nohidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcorpus_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_article_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-182-e2510c1ee8c0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marticle_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0marticle_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlistdir_nohidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcorpus_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_article_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-198-8410201fd184>\u001b[0m in \u001b[0;36mget_article_metadata\u001b[0;34m(article_file, size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.xml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_article_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mjournal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_plos_journal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mjats_article_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_article_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplos_article_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_plos_article_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-205-f0950144238a>\u001b[0m in \u001b[0;36mget_plos_journal\u001b[0;34m(article_file, caps_fixed)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error in journal name for {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcaps_fixed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mjournal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjournal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mjournal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plos'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mjournal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"PLOS\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "corpus_metadata = get_corpus_metadata(article_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_metadata_to_csv(corpus_metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
