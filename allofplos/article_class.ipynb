{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as et\n",
    "import os\n",
    "\n",
    "from plos_corpus import filename_to_doi\n",
    "from plos_regex import validate_doi, validate_filename\n",
    "from samples.corpus_analysis import parse_article_date\n",
    "\n",
    "# Main directory of article XML files\n",
    "corpusdir = 'allofplos_xml'\n",
    "\n",
    "# Temp folder for downloading and processing new articles\n",
    "newarticledir = 'new_plos_articles'\n",
    "\n",
    "# URL bases for PLOS's raw article XML\n",
    "EXT_URL_TMP = 'http://journals.plos.org/plosone/article/file?id={0}&type=manuscript'\n",
    "INT_URL_TMP = 'http://contentrepo.plos.org:8002/v1/objects/mogilefs-prod-repo?key={0}.XML'\n",
    "URL_TMP = EXT_URL_TMP\n",
    "\n",
    "\n",
    "class Article:\n",
    "    plos_prefix = ''\n",
    "\n",
    "    def __init__(self, doi, directory=None):\n",
    "        self.doi = doi\n",
    "        if directory is None:\n",
    "            self.directory = corpusdir\n",
    "        else:\n",
    "            self.directory = directory\n",
    "        self._tree = None\n",
    "        self._local = None\n",
    "\n",
    "    @property\n",
    "    def doi(self):\n",
    "        return self._doi\n",
    "\n",
    "    @doi.setter\n",
    "    def doi(self, d):\n",
    "        if validate_doi(d) is False:\n",
    "            raise Exception(\"Invalid format for PLOS DOI\")\n",
    "        self._doi = d\n",
    "\n",
    "    def get_path(self):\n",
    "        if 'annotation' in self.doi:\n",
    "            article_path = os.path.join(self.directory, 'plos.correction.' + self.doi.split('/')[-1] + '.xml')\n",
    "        else:\n",
    "            article_path = os.path.join(self.directory, self.doi.lstrip('10.1371/') + '.xml')\n",
    "        return article_path\n",
    "\n",
    "    def get_local_bool(self):\n",
    "        article_path = self.get_path()\n",
    "        return os.path.isfile(article_path)\n",
    "\n",
    "    def get_local_element_tree(self, article_path=None):\n",
    "        if article_path is None:\n",
    "            article_path = self.get_path()\n",
    "        if self.local:\n",
    "            local_element_tree = et.parse(article_path)\n",
    "            return local_element_tree\n",
    "        else:\n",
    "            print(\"Local article file not found: {}\".format(article_path))\n",
    "\n",
    "    def get_local_root_element(self, article_tree=None):\n",
    "        if article_tree is None:\n",
    "            article_tree = self.tree\n",
    "        root = article_tree.getroot()\n",
    "        return root\n",
    "\n",
    "    def get_local_xml(self, article_tree=None, pretty_print=True):\n",
    "        if article_tree is None:\n",
    "            article_tree = self.tree\n",
    "        local_xml = et.tostring(article_tree,\n",
    "                                method='xml',\n",
    "                                encoding='unicode',\n",
    "                                pretty_print=pretty_print)\n",
    "        return print(local_xml)\n",
    "\n",
    "    def get_url(self, plos_network=False):\n",
    "        URL_TMP = INT_URL_TMP if plos_network else EXT_URL_TMP\n",
    "        return URL_TMP.format(self.doi)\n",
    "\n",
    "    def get_remote_element_tree(self, url=None):\n",
    "        if url is None:\n",
    "            url = self.get_url()\n",
    "        remote_element_tree = et.parse(url)\n",
    "        return remote_element_tree\n",
    "\n",
    "    def get_remote_xml(self, article_tree=None, pretty_print=True):\n",
    "        if article_tree is None:\n",
    "            article_tree = self.get_remote_element_tree()\n",
    "        remote_xml = et.tostring(article_tree,\n",
    "                                 method='xml',\n",
    "                                 encoding='unicode',\n",
    "                                 pretty_print=pretty_print)\n",
    "        return print(remote_xml)\n",
    "\n",
    "    def get_element_xpath(self, article_root=None, tag_path_elements=None):\n",
    "        \"\"\"\n",
    "        For a local article's root element, grab particular sub-elements via XPath location\n",
    "        Defaults to reading the element location for uncorrected proofs/versions of record\n",
    "        :param article_root: the xml file for a single article\n",
    "        :param tag_path_elements: xpath location in the XML tree of the article file\n",
    "        :return: list of elements with that xpath location\n",
    "        \"\"\"\n",
    "        if article_root is None:\n",
    "            article_root = self.root\n",
    "        if tag_path_elements is None:\n",
    "            tag_path_elements = ('/',\n",
    "                                 'article',\n",
    "                                 'front',\n",
    "                                 'article-meta',\n",
    "                                 'custom-meta-group',\n",
    "                                 'custom-meta',\n",
    "                                 'meta-value')\n",
    "        tag_location = '/'.join(tag_path_elements)\n",
    "        return article_root.xpath(tag_location)\n",
    "\n",
    "    def get_proof_status(self):\n",
    "        \"\"\"\n",
    "        For a single article in a directory, check whether it is an 'uncorrected proof' or a\n",
    "        'VOR update' to the uncorrected proof, or neither\n",
    "        :return: proof status if it exists; otherwise, None\n",
    "        \"\"\"\n",
    "        xpath_results = self.get_element_xpath()\n",
    "        for result in xpath_results:\n",
    "            if result.text == 'uncorrected-proof':\n",
    "                return 'uncorrected_proof'\n",
    "            elif result.text == 'vor-update-to-uncorrected-proof':\n",
    "                return 'vor_update'\n",
    "            else:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "    def get_plos_journal(self, caps_fixed=True):\n",
    "        \"\"\"\n",
    "        For an individual PLOS article, get the journal it was published in.\n",
    "        :param caps_fixed: whether to render 'PLOS' in the journal name correctly or as-is ('PLoS')\n",
    "        :return: PLOS journal at specified xpath location\n",
    "        \"\"\"\n",
    "        try:\n",
    "            journal = self.get_element_xpath(tag_path_elements=[\"/\",\n",
    "                                                                \"article\",\n",
    "                                                                \"front\",\n",
    "                                                                \"journal-meta\",\n",
    "                                                                \"journal-title-group\",\n",
    "                                                                \"journal-title\"])\n",
    "            journal = journal[0].text\n",
    "        except IndexError:\n",
    "            # Need to file JIRA ticket: only affects pone.0047704\n",
    "            journal_meta = self.get_element_xpath(tag_path_elements=[\"/\",\n",
    "                                                                     \"article\",\n",
    "                                                                     \"front\",\n",
    "                                                                     \"journal-meta\"])\n",
    "            for journal_child in journal_meta[0]:\n",
    "                if journal_child.attrib['journal-id-type'] == 'nlm-ta':\n",
    "                    journal = journal_child.text\n",
    "                    break\n",
    "\n",
    "        if caps_fixed:\n",
    "            journal = journal.split()\n",
    "            if journal[0].lower() == 'plos':\n",
    "                journal[0] = \"PLOS\"\n",
    "            journal = (' ').join(journal)\n",
    "        return journal\n",
    "    \n",
    "    def get_article_title(self):\n",
    "        \"\"\"\n",
    "        For an individual PLOS article, get its title.\n",
    "        :return: string of article title at specified xpath location\n",
    "        \"\"\"\n",
    "        title = self.get_element_xpath(tag_path_elements=[\"/\",\n",
    "                                                          \"article\",\n",
    "                                                          \"front\",\n",
    "                                                          \"article-meta\",\n",
    "                                                          \"title-group\",\n",
    "                                                          \"article-title\"])\n",
    "        title_text = et.tostring(title[0], encoding='unicode', method='text', pretty_print=True)\n",
    "        return title_text.rstrip('\\n')\n",
    "    \n",
    "    def get_dates(self, string_=False, string_format='%Y-%m-%d', debug=False):\n",
    "        \"\"\"\n",
    "        For an individual article, get all of its dates, including publication date (pubdate), submission date\n",
    "        :return: tuple of dict of date types mapped to datetime objects for that article, dict for date strings if wrong order\n",
    "        \"\"\"\n",
    "        dates = {}\n",
    "\n",
    "        tag_path_1 = [\"/\",\n",
    "                      \"article\",\n",
    "                      \"front\",\n",
    "                      \"article-meta\",\n",
    "                      \"pub-date\"]\n",
    "        element_list_1 = self.get_element_xpath(tag_path_elements=tag_path_1)\n",
    "        for element in element_list_1:\n",
    "            pub_type = element.get('pub-type')\n",
    "            try:\n",
    "                date = parse_article_date(element)\n",
    "            except ValueError:\n",
    "                print('Error getting pubdates for {}'.format(article_file))\n",
    "                date = ''\n",
    "            dates[pub_type] = date\n",
    "\n",
    "        tag_path_2 = [\"/\",\n",
    "                      \"article\",\n",
    "                      \"front\",\n",
    "                      \"article-meta\",\n",
    "                      \"history\"]\n",
    "        element_list_2 = self.get_element_xpath(tag_path_elements=tag_path_2)\n",
    "        for element in element_list_2:\n",
    "            for part in element:\n",
    "                date_type = part.get('date-type')\n",
    "                try:\n",
    "                    date = parse_article_date(part)\n",
    "                except ValueError:\n",
    "                    print('Error getting history dates for {}'.format(article_file))\n",
    "                    date = ''\n",
    "                dates[date_type] = date\n",
    "        if debug:\n",
    "            # check whether date received is before date accepted is before pubdate\n",
    "            if dates.get('received', '') and dates.get('accepted', '') in dates:\n",
    "                if not dates['received'] <= dates['accepted'] <= dates['epub']:\n",
    "                    print('{}: dates in wrong order'.format(doi))\n",
    "\n",
    "        if string_:\n",
    "            # can return dates as strings instead of datetime objects if desired\n",
    "            for key, value in dates.items():\n",
    "                if value:\n",
    "                    dates[key] = value.strftime(string_format)\n",
    "\n",
    "        return dates\n",
    "\n",
    "    def get_pubdate(self, string_=False, string_format='%Y-%m-%d'):\n",
    "        dates = self.get_dates(string_=string_, string_format=string_format)\n",
    "        return dates['epub']\n",
    "\n",
    "    def get_jats_article_type(self):\n",
    "        \"\"\"\n",
    "        For an article file, get its JATS article type\n",
    "        Use primarily to find Correction (and thereby corrected) articles\n",
    "        :return: JATS article_type at that xpath location\n",
    "        \"\"\"\n",
    "        type_element_list = self.get_element_xpath(tag_path_elements=[\"/\",\n",
    "                                                                      \"article\"])\n",
    "        return type_element_list[0].attrib['article-type']\n",
    "\n",
    "    def get_plos_article_type(self):\n",
    "        \"\"\"\n",
    "        For an article file, get its PLOS article type. This format is less standardized than JATS article type\n",
    "        :return: PLOS article_type at that xpath location\n",
    "        \"\"\"\n",
    "        article_categories = self.get_element_xpath(tag_path_elements=[\"/\",\n",
    "                                                                       \"article\",\n",
    "                                                                       \"front\",\n",
    "                                                                       \"article-meta\",\n",
    "                                                                       \"article-categories\"])\n",
    "        subject_list = article_categories[0].getchildren()\n",
    "\n",
    "        for i, subject in enumerate(subject_list):\n",
    "            if subject.get('subj-group-type') == \"heading\":\n",
    "                subject_instance = subject_list[i][0]\n",
    "                s = ''\n",
    "                for text in subject_instance.itertext():\n",
    "                    s = s + text\n",
    "                    plos_article_type = s\n",
    "        return plos_article_type\n",
    "\n",
    "    def get_dtd(self):\n",
    "        \"\"\"\n",
    "        For more information on these DTD tagsets, see https://jats.nlm.nih.gov/1.1d3/ and https://dtd.nlm.nih.gov/3.0/\n",
    "        \"\"\"\n",
    "        try:\n",
    "            dtd = self.get_element_xpath(tag_path_elements=[\"/\",\n",
    "                                                            \"article\"])\n",
    "            dtd = dtd[0].attrib['dtd-version']\n",
    "            if str(dtd) == '3.0':\n",
    "                dtd = 'NLM 3.0'\n",
    "            elif dtd == '1.1d3':\n",
    "                dtd = 'JATS 1.1d3'\n",
    "        except KeyError:\n",
    "            print('Error parsing DTD from', self.doi)\n",
    "            dtd = 'N/A'\n",
    "        return dtd\n",
    "    \n",
    "    \n",
    "\n",
    "    @property\n",
    "    def xml(self):\n",
    "        return self.get_local_xml()\n",
    "\n",
    "    @property\n",
    "    def tree(self):\n",
    "        if self._tree is None:\n",
    "            return self.get_local_element_tree()\n",
    "        else:\n",
    "            return self._tree\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        return self.get_local_root_element()\n",
    "\n",
    "    @property\n",
    "    def url(self):\n",
    "        return self.get_url(plos_network=self.plos_network)\n",
    "\n",
    "    @property\n",
    "    def filename(self):\n",
    "        return self.get_path()\n",
    "\n",
    "    @property\n",
    "    def local(self):\n",
    "        if self._local is None:\n",
    "            return self.get_local_bool()\n",
    "        else:\n",
    "            return self._local\n",
    "\n",
    "    @property\n",
    "    def proof(self):\n",
    "        return self.get_proof_status()\n",
    "\n",
    "    @property\n",
    "    def journal(self):\n",
    "        return self.get_plos_journal()\n",
    "    \n",
    "    @property\n",
    "    def title(self):\n",
    "        return self.get_article_title()\n",
    "    \n",
    "    @property\n",
    "    def pubdate(self):\n",
    "        return self.get_pubdate()\n",
    "\n",
    "    @property\n",
    "    def type_(self):\n",
    "        return self.get_jats_article_type()\n",
    "\n",
    "    @property\n",
    "    def plostype(self):\n",
    "        return self.get_plos_article_type()\n",
    "\n",
    "    @property\n",
    "    def dtd(self):\n",
    "        return self.get_dtd()\n",
    "\n",
    "    @filename.setter\n",
    "    def filename(self, value):\n",
    "        self.doi = filename_to_doi(value)\n",
    "\n",
    "    @classmethod\n",
    "    def from_filename(cls, filename):\n",
    "        return cls(filename_to_doi(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from samples.corpus_analysis import get_random_list_of_dois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural coding in the visual system of Drosophila melanogaster: How do small neural populations support visually guided behaviours?'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = Article('10.1371/journal.pcbi.1005735')\n",
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-10-10'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.get_pubdate(string_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.get_element_xpath()[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article.from_filename(article1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article('10.1371/journal.pone.1234567')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_file = listdir_nohidden(corpusdir)[78357]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article.from_filename('allofplos_xml/journal.pone.0052089.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correction\n",
      "correction\n",
      "correction\n",
      "correction\n",
      "correction\n",
      "correction\n",
      "correction\n",
      "review-article\n",
      "correction\n",
      "correction\n",
      "correction\n",
      "correction\n",
      "book-review\n",
      "article-commentary\n",
      "correction\n",
      "correction\n",
      "correction\n",
      "discussion\n",
      "correction\n",
      "discussion\n",
      "discussion\n",
      "discussion\n",
      "correction\n",
      "correction\n",
      "discussion\n",
      "correction\n",
      "correction\n",
      "letter\n",
      "correction\n",
      "correction\n",
      "other\n",
      "correction\n",
      "correction\n",
      "correction\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a59a59a0bf2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdois\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArticle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"research-article\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-f380fba56e61>\u001b[0m in \u001b[0;36mtype_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_jats_article_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dois = get_random_list_of_dois(count=10000)\n",
    "for doi in dois:\n",
    "    article = Article(doi)\n",
    "    if article.type_ != \"research-article\":\n",
    "        print(article.type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "bar = progressbar.ProgressBar(redirect_stdout=True, max_value=len(dois))\n",
    "uncorrected_class_proof_list = []\n",
    "for i, doi in enumerate(dois):\n",
    "    article = Article(doi)\n",
    "    if article.proof == 'uncorrected_proof':\n",
    "        uncorrected_class_proof_list.append(doi)\n",
    "    bar.update(i+1)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "uncorrected_function_proof_list = []\n",
    "bar = progressbar.ProgressBar(redirect_stdout=True, max_value=len(dois))\n",
    "for i, doi in enumerate(dois):\n",
    "    if check_if_uncorrected_proof(doi):\n",
    "        uncorrected_function_proof_list.append(doi)\n",
    "    bar.update(i+1)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uncorrected_class_proof_list, uncorrected_function_proof_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
